{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing in Databases\n",
    "\n",
    "In order to efficiently find the value for a particular key in the database, we need a\n",
    "different data structure: **an index** where the the general idea behind them is to keep some\n",
    "additional metadata on the side, which acts as a signpost and helps you to locate the data you want.\n",
    "\n",
    "An index is an additional structure that is derived from the primary data. Many data‚Äê\n",
    "bases allow you to add and remove indexes, and this doesn‚Äôt affect the contents of the\n",
    "database; it only affects the performance of queries. Maintaining additional structures\n",
    "incurs overhead, especially on writes. For writes, it‚Äôs hard to beat the performance of\n",
    "simply appending to a file, because that‚Äôs the simplest possible write operation. Any\n",
    "kind of index usually slows down writes, because the index also needs to be updated\n",
    "every time data is written.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hash Indexes\n",
    "\n",
    "A simple key value pair index. Let‚Äôs say our data storage consists only of appending to a file, as in the preceding example. Then the simplest possible indexing strategy is this: keep an in-memory\n",
    "hash map where every key is mapped to a byte offset in the data file‚Äîthe location at\n",
    "which the value can be found. Whenever you append a\n",
    "new key-value pair to the file, you also update the hash map to reflect the offset of the\n",
    "data you just wrote (this works both for inserting new keys and for updating existing\n",
    "keys). When you want to look up a value, use the hash map to find the offset in the\n",
    "data file, seek to that location, and read the value.\n",
    "\n",
    "\n",
    "**Tombstone:** If you want to delete a key and its associated value, you have to append a special\n",
    "deletion record to the data file (sometimes called a tombstone). When log seg‚Äê\n",
    "ments are merged, the tombstone tells the merging process to discard any previ‚Äê\n",
    "ous values for the deleted key.\n",
    "\n",
    "**Crash Recovery:**\n",
    "If the database is restarted, the in-memory hash maps are lost. In principle, you\n",
    "can restore each segment‚Äôs hash map by reading the entire segment file from\n",
    "beginning to end and noting the offset of the most recent value for every key as\n",
    "you go along. However, that might take a long time if the segment files are large,\n",
    "which would make server restarts painful. To avoid this we can snapshot of each segment‚Äôs hash map on disk, which can be loaded into memory more quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashIndex:\n",
    "    def __init__(self, name):\n",
    "        self.name = f\"data/{name}.index\" # Filename\n",
    "        self.index = {}\n",
    "        \n",
    "# Regenerate In-memory index From file if does not exist\n",
    "\n",
    "    def set_val(self, key, value):\n",
    "        # Write to file and save offset\n",
    "        with open(self.name, 'a') as f:\n",
    "            f.seek(0, 2) # first line from the end\n",
    "            end_offset = f.tell() # end offset\n",
    "            f.write(f\"{key}{value}\")\n",
    "        # create index using offset\n",
    "        self.index[key] = {\n",
    "            \"offset\": end_offset,\n",
    "            \"pk_size\": len(f\"{key}\"), \n",
    "            \"data_size\": len(f\"{value}\"), \n",
    "            \"data\": value\n",
    "        }\n",
    "        \n",
    "    def get_val(self, key):\n",
    "        # Read from Offset and length\n",
    "        try:\n",
    "            key_index = self.index[key]\n",
    "        except:\n",
    "            return \"<NAN>\"\n",
    "        with open(self.name) as f:\n",
    "            char = f.seek(key_index[\"offset\"] + key_index[\"pk_size\"])\n",
    "            return f.readline(key_index[\"data_size\"])\n",
    "\n",
    "    def del_val(self,key):\n",
    "        key_index = self.index[key]\n",
    "        with open(self.name, 'a') as f:\n",
    "            char = f.seek(key_index[\"offset\"])\n",
    "            # Tombstone\n",
    "            f.write(f\"{key}{'üíÄ'}\")\n",
    "        self.index.pop(key, None)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"1\": {\n",
      "        \"data\": {\n",
      "            \"name\": \"bheem\"\n",
      "        },\n",
      "        \"data_size\": 17,\n",
      "        \"offset\": 0,\n",
      "        \"pk_size\": 1\n",
      "    },\n",
      "    \"2\": {\n",
      "        \"data\": \"\\ud83d\\ude0e\",\n",
      "        \"data_size\": 1,\n",
      "        \"offset\": 18,\n",
      "        \"pk_size\": 1\n",
      "    },\n",
      "    \"3\": {\n",
      "        \"data\": \"Some Stupid String\",\n",
      "        \"data_size\": 18,\n",
      "        \"offset\": 23,\n",
      "        \"pk_size\": 1\n",
      "    },\n",
      "    \"4\": {\n",
      "        \"data\": 120293292939393,\n",
      "        \"data_size\": 15,\n",
      "        \"offset\": 42,\n",
      "        \"pk_size\": 1\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "infile = HashIndex(\"hash_test\")\n",
    "infile.set_val(1, {\"name\":\"bheem\"}) # Dict\n",
    "infile.set_val(2, \"üòé\") # Emoji\n",
    "infile.set_val(3, \"Some Stupid String\") # Dict\n",
    "infile.set_val(4, 120293292939393) # Big Number\n",
    "print(json.dumps(infile.index, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create\n",
    "assert infile.get_val(1) == \"{'name': 'bheem'}\"\n",
    "assert infile.get_val(2) == 'üòé'\n",
    "assert infile.get_val(3) == 'Some Stupid String'\n",
    "assert infile.get_val(4) == '120293292939393'\n",
    "# Update\n",
    "infile.set_val(4, 'update 4th index') # Big Number\n",
    "assert infile.get_val(4) == 'update 4th index'\n",
    "# Delete\n",
    "infile.del_val(4)\n",
    "assert infile.get_val(4) == '<NAN>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## log-structured indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B-Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multidimensional Indexes (GIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full text search & Fuzzy Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
